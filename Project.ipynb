{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I am working on advanced lane finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am showing the structure of the notebook and also acknowledging the sources I took help from, for each section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Camera Calibration](#camera_calibration) - ***./examples/example.ipynb***\n",
    "2. [Undistort Image](#undistort_image) - ***lesson 6 Part 12 quiz solution***\n",
    "3. [Perspective Transform](#perspective_transform) - ***Jeremy shannon project [here](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb)***\n",
    "4. [Convert RGB image into Binary](#convert_to_binary) - ***lesson 7 part 12 quiz solution***\n",
    "5. [Finding Lane Pixels](#finding_lane_pixels) - ***Lesson 8 Part 4 quiz solution***\n",
    "6. [Radius Of Curvature](#radius_of_curvature) - ***Lesson 8 part 7 quiz solution***\n",
    "7. [Testing on Test Images](#testing_on_test_images) -  ***putting text code block was from jeremy shannons blog***\n",
    "8. [Video Pipeline](#video_pipeline) - ***putting text code block was from jeremy shannons blog***\n",
    "9. [Search from Prior](#search_prior) ***Lesson 8 Part 5 quiz solution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from camera import Camera\n",
    "from preprocess import PerspectiveTransformer\n",
    "import util\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lane_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3cb84854aa58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlane_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLaneDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lane_utils'"
     ]
    }
   ],
   "source": [
    "from lane import LaneDetector\n",
    "from util import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = LaneDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_transform(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = pt.transform(img)\n",
    "    img = bt.transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"camera_calibration\">\n",
    "</a>\n",
    "\n",
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section , I am writing code to calibrate camera. I have used codes from the ```example.ipynb``` provided with this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we are calculating the calibration matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 720\n",
    "W = 1280\n",
    "IMG_SIZE = (H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal_output_dir = \"result/camera_cal/\"\n",
    "os.makedirs(camera_cal_output_dir, exist_ok=True)\n",
    "\n",
    "undistort_output_dir = \"result/undistort/\"\n",
    "os.makedirs(undistort_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = util.load_img_from_dir(\"camera_cal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs):\n",
    "    camera.set_img_points(img, plot=True, save_fig=True, fig_name=os.path.join(camera_cal_output_dir,\"{}.jpg\".format(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_matrix, _ = camera.get_calibration_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(calibration_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The undistorted images. Note: not all undistortions are noticeable as not all distortions can be noticed easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = util.load_img_from_dir('camera_cal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in tqdm.tqdm(enumerate(imgs)):\n",
    "    undist = camera.undistort(img)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image')\n",
    "    plt.savefig(os.path.join(undistort_output_dir, \"image_{}\".format(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following images undistortion is clearly noticeable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![undistorted4](undistort_result/camera_cal/calibration1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this following image, it is not that noticeable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![undistorted3](undistort_result/camera_cal/calibration10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"undistort_image\"></a>\n",
    "### Undistort Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took help from the ***lesson 6 Part 12 quiz solution***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'test_images/test2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = util.imread(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undistort it using the calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = camera.undistort(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/undistorted_test_image.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"perspective_transform\"></a>\n",
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the image in a grid for getting the four points for the perspective transform. I took help from the project done by Jeremy shannon which is referenced [here](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PerspectiveTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.tune(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transformed = pt.transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/image_transformed.jpg',img_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =\"convert_to_binary\"></a>\n",
    "## Convert to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import BinaryTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BinaryTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [pt.transform(img) for img in util.load_img_from_dir('test_images')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_config_file = \"config.yaml\"\n",
    "if not os.path.exists(binary_config_file):\n",
    "    bt.tune_imgs(test_imgs)\n",
    "else:\n",
    "    bt.load_config(binary_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bt.s_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bt.sobel_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = bt.r2b(img_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the actual image and binary. This is also taken from lesson 7 part 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.tight_layout()\n",
    "ax1.imshow(img_transformed)\n",
    "ax1.set_title('Original Image')\n",
    "ax2.imshow(binary, cmap='gray')\n",
    "ax2.set_title('Binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/binary.jpg',binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"finding_lane_pixels\"></a>\n",
    "### Finding Lane pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to find out pixels of a lane. I took help from the ***Lesson 8 Part 4*** quiz solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out_img,left_fitx,right_fitx,ploty,left_fit,right_fit = ld.fit(binary)\n",
    "plt.plot(left_fitx, ploty, color='red')\n",
    "plt.plot(right_fitx, ploty, color='blue')\n",
    "plt.imshow(img_transformed)\n",
    "plt.title('Lanes')\n",
    "plt.savefig('result/image_transformed_with_lane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw the lanes in the original picture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I took help from jeremy shannon's [project](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb) for this section***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lane = ld.draw_lane(img,binary,left_fitx,right_fitx,ploty,pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_lane)\n",
    "plt.savefig('result/image_lane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =\"radius_of_curvature\"></a>\n",
    "## Radius of curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the radius of curvature. I took help from ***Lesson 8 part 7 quiz solution*** for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curverad,right_curverad,vehicle_position = measure_curvature_pos(ploty, left_fitx, right_fitx, binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curvature radius is the average of the left lane and right lane radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_radius = (left_curverad+right_curverad)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Curvature radius {} m , and vehicle position w.r.t lane midpoint {} m\".format(curv_radius,vehicle_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "cv2.putText(image_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "image_lane = cv2.putText(image_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(image_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/detected_lane_with_radius_position.jpg',image_lane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing_on_test_images\"></a>\n",
    "## Testing on the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_image_name in test_images:\n",
    "    test_image = util.imread(test_image_name)\n",
    "    test_image_transformed = pt.transform(test_image)\n",
    "    binary = bt.r2b(test_image_transformed)\n",
    "    out_img,left_fitx,right_fitx,ploty,left_fit,right_fit = ld.fit(binary)\n",
    "    test_image_lane = ld.draw_lane(test_image,binary,left_fitx,right_fitx,ploty,pt)\n",
    "    left_curverad,right_curverad,vehicle_position = measure_curvature_pos(ploty,left_fitx,right_fitx,binary) \n",
    "    curv_radius = (left_curverad+right_curverad) / 2\n",
    "    \n",
    "    text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "    cv2.putText(test_image_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "    cv2.putText(test_image_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    f, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4, figsize=(24,9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(test_image)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax2.imshow(test_image_transformed)\n",
    "    ax2.set_title('Transformed Image')\n",
    "    ax3.imshow(out_img, cmap='gray')\n",
    "    ax3.set_title('Binary')\n",
    "    ax4.imshow(test_image_lane, cmap='gray')\n",
    "    ax4.set_title('Detected Lane')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"video_pipeline\"></a>\n",
    "## Video Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"search_prior\"></a>\n",
    "### But wait!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ***lesson 8 Part 5*** we learned that not all pixels in every frame is necessary to search the lane. It is enough to search around the previously detected lanes. so at first, let's get the polynomial coefficients for the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_search(binary_frame,left_fit,right_fit,margin=50):\n",
    "    nonzero = binary_frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_indices = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_indices = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    leftx = nonzerox[left_lane_indices]\n",
    "    lefty = nonzeroy[left_lane_indices]\n",
    "    rightx = nonzerox[right_lane_indices]\n",
    "    righty = nonzeroy[right_lane_indices]\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, binary_frame.shape[0]-1, binary_frame.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return left_fitx,right_fitx,ploty,left_fit,right_fit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets close the video object and read it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('project_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the width and height of the video to create the ```VideoWriter``` object for output of the video\n",
    "\n",
    "I took help for the following code from this [link](https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('project_output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing display and widgets module for display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the coefficients for the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = cap.read()\n",
    "binary_frame = all_transform(frame)\n",
    "frame_output,left_fitx,right_fitx,ploty,left_fit,right_fit = fit(binary_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Class for tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested in the lessons, I am declaring the line class to track the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line= Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ret:    \n",
    "    if left_line.detected ==False or right_line.detected==False:\n",
    "        frame_output,left_fitx,right_fitx,ploty,left_fit,right_fit = ld.fit(binary_frame)    \n",
    "    else:\n",
    "        left_fitx,right_fitx,ploty,left_fit,right_fit = prior_search(binary_frame,left_fit,right_fit,margin=150)\n",
    "    if abs(abs(left_fitx[-1]-right_fitx[-1])-500)<100:\n",
    "        left_line.detected=False\n",
    "        right_line.detected=False\n",
    "        left_line.fit(left_fit)\n",
    "        right_line.fit(right_fit)\n",
    "        left_best_fitx=left_line.get_fitx(ploty)\n",
    "        right_best_fitx=right_line.get_fitx(ploty)\n",
    "    \n",
    "    frame_lane = draw_lane(frame,binary_frame,left_best_fitx,right_best_fitx,ploty, pt)\n",
    "    left_curverad,right_curverad,vehicle_position=measure_curvature_pos(ploty,left_best_fitx,right_best_fitx,binary_frame) \n",
    "    curv_radius = (left_curverad+right_curverad)/2\n",
    "    text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "    cv2.putText(frame_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "    cv2.putText(frame_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    out.write(frame_lane)\n",
    "    diff = left_curverad-right_curverad\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        binary_frame = all_transform(frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
