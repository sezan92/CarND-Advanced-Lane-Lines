{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I am working on advanced lane finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am showing the structure of the notebook and also acknowledging the sources I took help from, for each section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Camera Calibration](#camera_calibration) - ***./examples/example.ipynb***\n",
    "2. [Undistort Image](#undistort_image) - ***lesson 6 Part 12 quiz solution***\n",
    "3. [Perspective Transform](#perspective_transform) - ***Jeremy shannon project [here](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb)***\n",
    "4. [Convert RGB image into Binary](#convert_to_binary) - ***lesson 7 part 12 quiz solution***\n",
    "5. [Finding Lane Pixels](#finding_lane_pixels) - ***Lesson 8 Part 4 quiz solution***\n",
    "6. [Radius Of Curvature](#radius_of_curvature) - ***Lesson 8 part 7 quiz solution***\n",
    "7. [Testing on Test Images](#testing_on_test_images) -  ***putting text code block was from jeremy shannons blog***\n",
    "8. [Video Pipeline](#video_pipeline) - ***putting text code block was from jeremy shannons blog***\n",
    "9. [Search from Prior](#search_prior) ***Lesson 8 Part 5 quiz solution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from camera import Camera\n",
    "import util\n",
    "import os\n",
    "%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"camera_calibration\">\n",
    "</a>\n",
    "\n",
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section , I am writing code to calibrate camera. I have used codes from the ```example.ipynb``` provided with this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we are calculating the calibration matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 720\n",
    "W = 1280\n",
    "IMG_SIZE = (H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_cal_output_dir = \"result/camera_cal/\"\n",
    "os.makedirs(camera_cal_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = util.load_img_from_dir(\"camera_cal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs):\n",
    "    camera.set_img_points(img, plot=True, save_fig=True, fig_name=os.path.join(camera_cal_output_dir,\"{}.jpg\".format(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_matrix, _ = camera.get_calibration_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(calibration_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The undistorted images. Note: not all undistortions are noticeable as not all distortions can be noticed easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in tqdm.tqdm(image_names):\n",
    "    image = cv2.imread(image_name)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objectpoints, imagepoints, img_size,None,None)\n",
    "    undist = cv2.undistort(image,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image')\n",
    "    plt.savefig(\"undistort_result/{}\".format(image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following images undistortion is clearly noticeable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![undistorted4](undistort_result/camera_cal/calibration1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this following image, it is not that noticeable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![undistorted3](undistort_result/camera_cal/calibration10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"undistort_image\"></a>\n",
    "### Undistort Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took help from the ***lesson 6 Part 12 quiz solution***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 'test_images/test2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it into RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undistort it using the calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.undistort(image,cameraMatrix,distCoeffs,None,cameraMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/undistorted_test_image.jpg',image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"perspective_transform\"></a>\n",
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the image in a grid for getting the four points for the perspective transform. I took help from the project done by Jeremy shannon which is referenced [here](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, wer see, that, the lane lines are forming a trapizium of points (575,480) ,(750,480),(300,700),(1100,700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.imshow(image)\n",
    "plt.plot([575,750,300,1100],[480,480,700,700],'r*',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want it to transform such that, we get the lane lines as parallel as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining source points. I hardcoded the source and destination points based on my own trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.float32([(575,480),\n",
    "                  (750,480), \n",
    "                  (300,700), \n",
    "                  (1100,700)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination points . The points will be how we want to see our birds eye view. lets select the 4 point of our birds eye view as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W,C = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = np.float32([(400,0), #top left\n",
    "                  (W-400,0), #top right\n",
    "                  (400,H), #bottom left\n",
    "                  (W-400,H)]) #bottom right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getPerspectiveTransform(source, destination)\n",
    "image_transformed = cv2.warpPerspective(image, M, (W,H), flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make one funciton to read and undistort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will give the transformed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image,source,destination):\n",
    "    M = cv2.getPerspectiveTransform(source, destination)\n",
    "    image_transformed = cv2.warpPerspective(image, M, (W,H), flags=cv2.INTER_LINEAR)\n",
    "    return image_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(image_name,cameraMatrix=cameraMatrix,distCoeffs=distCoeffs):\n",
    "    image = cv2.imread(image_name)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.undistort(image,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets transform the image to get the birds eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformed = perspective_transform(image,source,destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets retransform to actual perspective and see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_transform = perspective_transform(image_transformed,destination,source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(previous_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.cvtColor(image_transformed,cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('result/image_transformed.jpg',image_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =\"convert_to_binary\"></a>\n",
    "## Convert to Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to HLS color space and then to binary image. I took help from the quiz of ***lesson 7 part 12.*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(image=fixed(image_transformed),s1=(0,255),s2=(0,255),sx1=(0,255),sx2=(0,255),plot=fixed(True))\n",
    "def r2b(image,s1=150,s2=230 ,sx1=89,sx2=220,plot=False ):\n",
    "    s_thresh=(s1,s2)\n",
    "    sx_thresh=(sx1,sx2)\n",
    "    image = np.copy(image)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelx = np.absolute(sobelx) \n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    if plot:\n",
    "        plt.imshow(combined_binary)\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = r2b(image_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the actual image and binary. This is also taken from lesson 7 part 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "f.tight_layout()\n",
    "ax1.imshow(image_transformed)\n",
    "ax1.set_title('Original Image')\n",
    "ax2.imshow(binary, cmap='gray')\n",
    "ax2.set_title('Binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/binary.jpg',binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"finding_lane_pixels\"></a>\n",
    "### Finding Lane pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to find out pixels of a lane. I took help from the ***Lesson 8 Part 4*** quiz solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lane(binary):\n",
    "    histogram = np.sum(binary[binary.shape[0]//2:,:], axis=0)\n",
    "    out_img = np.dstack((binary, binary, binary))\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    nwindows = 10\n",
    "    margin = 120\n",
    "    minpix = 50\n",
    "\n",
    "    window_height = np.int(binary.shape[0]//nwindows)\n",
    "    nonzero = binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    for window in range(nwindows):\n",
    "        win_y_low = binary.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current -margin  \n",
    "        win_xleft_high = leftx_current+margin  \n",
    "        win_xright_low = rightx_current -margin  \n",
    "        win_xright_high = rightx_current+margin  \n",
    "        \n",
    "\n",
    "        \n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary):\n",
    "    leftx, lefty, rightx, righty, out_img = detect_lane(binary)\n",
    "\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    \n",
    "    ploty = np.linspace(0, binary.shape[0]-1, binary.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    return out_img,left_fitx,right_fitx,ploty,left_fit,right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img,left_fitx,right_fitx,ploty,left_fit,right_fit = fit_polynomial(binary)\n",
    "plt.plot(left_fitx, ploty, color='red')\n",
    "plt.plot(right_fitx, ploty, color='blue')\n",
    "plt.imshow(image_transformed)\n",
    "plt.title('Lanes')\n",
    "plt.savefig('result/image_transformed_with_lane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw the lanes in the original picture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I took help from jeremy shannon's [project](https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb) for this section***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first lets create an empty mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(binary).astype(np.uint8)\n",
    "mask_color= np.dstack((mask,mask,mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make an array of left lane points and right lane points. Here we will have to transpose after stacking them , as in the opencv images have y dimension or number of rows are counted first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_left = np.array([np.transpose(np.vstack([left_fitx,ploty]))])\n",
    "points_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "points = np.hstack((points_left,points_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fill the polygon of the points with color green ,and the color the lanes as Red and Blue respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_color=cv2.fillPoly(mask_color,np.int32([points]),(0,255,0))\n",
    "mask_color=cv2.polylines(mask_color, np.int32([points_left]), isClosed=False, color=(255,0,0), thickness=10)\n",
    "mask_color=cv2.polylines(mask_color, np.int32([points_right]), isClosed=False, color=(0,0,255), thickness=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets transform the mask into original perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_color_previous = perspective_transform(mask_color,destination,source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_color_previous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets show the mask in the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lane = cv2.addWeighted(image,1,mask_color_previous,0.5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_lane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its better for future use to make single function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane(image,binary,left_fitx,right_fitx,ploty,source=source,destination=destination):\n",
    "    mask = np.zeros_like(binary).astype(np.uint8)\n",
    "    mask_color= np.dstack((mask,mask,mask))\n",
    "    points_left = np.array([np.transpose(np.vstack([left_fitx,ploty]))])\n",
    "    points_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    points = np.hstack((points_left,points_right))\n",
    "    mask_color=cv2.fillPoly(mask_color,np.int32([points]),(0,255,0))\n",
    "    mask_color=cv2.polylines(mask_color, np.int32([points_left]), isClosed=False, color=(255,0,0), thickness=15)\n",
    "    mask_color=cv2.polylines(mask_color, np.int32([points_right]), isClosed=False, color=(0,0,255), thickness=15)\n",
    "    mask_color_previous = perspective_transform(mask_color,destination,source)\n",
    "    image_lane = cv2.addWeighted(image,1,mask_color_previous,0.5,0)\n",
    "    return image_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lane = draw_lane(image,binary,left_fitx,right_fitx,ploty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_lane)\n",
    "plt.savefig('result/image_lane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =\"radius_of_curvature\"></a>\n",
    "## Radius of curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the radius of curvature. I took help from ***Lesson 8 part 7 quiz solution*** for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_pos(ploty,left_fitx,right_fitx,binary):\n",
    "    xm_per_pix = 3.7/550\n",
    "    ym_per_pix = 3.1/720\n",
    "    \n",
    "    left_fit = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)  \n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "   \n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    H,W = binary.shape\n",
    "    H= H*ym_per_pix\n",
    "    left_lane_intercept =  left_fit[0]*H**2 + left_fit[1]*H + left_fit[2]\n",
    "    right_lane_intercept = right_fit[0]*H**2 + right_fit[1]*H + right_fit[2]\n",
    "    \n",
    "    \n",
    "    lane_mid_point = (left_lane_intercept+right_lane_intercept)/2\n",
    "    \n",
    "    vehicle_mid_point = W/2*xm_per_pix\n",
    "    vehicle_position = lane_mid_point-vehicle_mid_point\n",
    "    \n",
    "    return left_curverad,right_curverad,vehicle_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curverad,right_curverad,vehicle_position = measure_curvature_pos(ploty,left_fitx,right_fitx,binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curvature radius is the average of the left lane and right lane radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_radius = (left_curverad+right_curverad)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Curvature radius {} m , and vehicle position w.r.t lane midpoint {} m\".format(curv_radius,vehicle_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "cv2.putText(image_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "cv2.putText(image_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(image_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result/detected_lane_with_radius_position.jpg',image_lane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing_on_test_images\"></a>\n",
    "## Testing on the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_image_name in test_images:\n",
    "    test_image = imread(test_image_name)\n",
    "    test_image_transformed = perspective_transform(test_image,source,destination)\n",
    "    binary = r2b(test_image_transformed)\n",
    "    out_img,left_fitx,right_fitx,ploty,left_fit,right_fit = fit_polynomial(binary)\n",
    "    test_image_lane = draw_lane(test_image,binary,left_fitx,right_fitx,ploty)\n",
    "    left_curverad,right_curverad,vehicle_position=measure_curvature_pos(ploty,left_fitx,right_fitx,binary) \n",
    "    curv_radius = (left_curverad+right_curverad)/2\n",
    "    \n",
    "    text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "    cv2.putText(test_image_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "    cv2.putText(test_image_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    f, (ax1, ax2, ax3,ax4) = plt.subplots(1, 4, figsize=(24,9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(test_image)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax2.imshow(test_image_transformed)\n",
    "    ax2.set_title('Transformed Image')\n",
    "    ax3.imshow(out_img, cmap='gray')\n",
    "    ax3.set_title('Binary')\n",
    "    ax4.imshow(test_image_lane, cmap='gray')\n",
    "    ax4.set_title('Detected Lane')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"video_pipeline\"></a>\n",
    "## Video Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('project_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"search_prior\"></a>\n",
    "### But wait!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ***lesson 8 Part 5*** we learned that not all pixels in every frame is necessary to search the lane. It is enough to search around the previously detected lanes. so at first, let's get the polynomial coefficients for the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = cap.read()\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.undistort(frame,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "frame_transformed = perspective_transform(frame,source,destination)\n",
    "binary_frame = r2b(frame_transformed)\n",
    "frame_output,left_fitx,right_fitx,ploty,left_fit,right_fit = fit_polynomial(binary_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's get the next frame and make it binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = cap.read()\n",
    "\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.undistort(frame,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "frame_transformed = perspective_transform(frame,source,destination)\n",
    "binary_frame = r2b(frame_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's get the nonzero values in y and x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero = binary_frame.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,let's get the possible left lane and right lane indices within margin of 50 pixels. [ I took this codeblock from ***lesson 8 Part 5*** quiz solution. ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 50 #margin for searching the lanes\n",
    "left_lane_indices = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "right_lane_indices = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the left lane and right lane pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftx = nonzerox[left_lane_indices]\n",
    "lefty = nonzeroy[left_lane_indices]\n",
    "rightx = nonzerox[right_lane_indices]\n",
    "righty = nonzeroy[right_lane_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's get new polynomial coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploty = np.linspace(0, binary_frame.shape[0]-1, binary_frame.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = np.dstack((binary_frame,binary_frame,binary_frame))*255\n",
    "output_image[nonzeroy[left_lane_indices], nonzerox[left_lane_indices]] = [255, 0, 0]\n",
    "output_image[nonzeroy[right_lane_indices], nonzerox[right_lane_indices]] = [0, 0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.imshow(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Let's make it a function to use it always!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_search(binary_frame,left_fit,right_fit,margin=50):\n",
    "    nonzero = binary_frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_indices = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_indices = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    leftx = nonzerox[left_lane_indices]\n",
    "    lefty = nonzeroy[left_lane_indices]\n",
    "    rightx = nonzerox[right_lane_indices]\n",
    "    righty = nonzeroy[right_lane_indices]\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, binary_frame.shape[0]-1, binary_frame.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return left_fitx,right_fitx,ploty,left_fit,right_fit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets close the video object and read it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('project_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the width and height of the video to create the ```VideoWriter``` object for output of the video\n",
    "\n",
    "I took help for the following code from this [link](https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('project_output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing display and widgets module for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "imgbox = widgets.Image(format='jpg',height=300,width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the coefficients for the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,frame = cap.read()\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.undistort(frame,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "frame_transformed = perspective_transform(frame,source,destination)\n",
    "binary_frame = r2b(frame_transformed)\n",
    "frame_output,left_fitx,right_fitx,ploty,left_fit,right_fit = fit_polynomial(binary_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Class for tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suggested in the lessons, I am declaring the line class to track the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "         \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n",
    "        \n",
    "        #recent number of values\n",
    "        self.n=15\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = deque(maxlen=self.n) \n",
    "        \n",
    "    def fit(self,fit):\n",
    "        if self.best_fit is not None:\n",
    "            diff = fit-self.best_fit\n",
    "            if (abs(self.diffs[0]) > 0.001 or \\\n",
    "               abs(self.diffs[1]) > 1.0 or \\\n",
    "               abs(self.diffs[2]) > 100):\n",
    "                self.detected = False\n",
    "            else:\n",
    "                self.current_fit.append(fit)\n",
    "                self.best_fit = np.average(self.current_fit,axis=0)\n",
    "                self.detected = True\n",
    "        else:\n",
    "            self.best_fit=fit\n",
    "            self.current_fit.append(fit)\n",
    "            self.detected= True\n",
    "    def get_fitx(self,ploty): \n",
    "        best_fitx = self.best_fit[0]*ploty**2 + self.best_fit[1]*ploty + self.best_fit[2]\n",
    "        return best_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count=1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line= Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(imgbox)\n",
    "left_line.fit(left_fit)\n",
    "right_line.fit(right_fit)\n",
    "left_best_fitx=left_line.get_fitx(ploty)\n",
    "right_best_fitx=right_line.get_fitx(ploty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fitx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_fitx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ret:\n",
    "    \n",
    "    \n",
    "    \n",
    "    if left_line.detected ==False or right_line.detected==False:\n",
    "\n",
    "        frame_output,left_fitx,right_fitx,ploty,left_fit,right_fit = fit_polynomial(binary_frame)\n",
    "        \n",
    "    else:\n",
    "        left_fitx,right_fitx,ploty,left_fit,right_fit = prior_search(binary_frame,left_fit,right_fit,margin=200)\n",
    "    \n",
    "    if abs(abs(left_fitx[-1]-right_fitx[-1])-500)<100:\n",
    "        left_line.detected=False\n",
    "        right_line.detected=False\n",
    "        left_line.fit(left_fit)\n",
    "        right_line.fit(right_fit)\n",
    "        left_best_fitx=left_line.get_fitx(ploty)\n",
    "        right_best_fitx=right_line.get_fitx(ploty)\n",
    "    \n",
    "    frame_lane = draw_lane(frame,binary_frame,left_best_fitx,right_best_fitx,ploty)\n",
    "    left_curverad,right_curverad,vehicle_position=measure_curvature_pos(ploty,left_best_fitx,right_best_fitx,binary_frame) \n",
    "    curv_radius = (left_curverad+right_curverad)/2\n",
    "    text=\"Curve radius {:04.2f} m\".format(curv_radius)\n",
    "    cv2.putText(frame_lane, text, (50,70), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    text=\"vehicle position w.r.t center {:04.2f} m\".format(vehicle_position)\n",
    "    cv2.putText(frame_lane, text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "    frame_lane = cv2.cvtColor(frame_lane,cv2.COLOR_RGB2BGR)\n",
    "    imgbox.value = frame_lane.tobytes()\n",
    "    out.write(frame_lane)\n",
    "    diff = left_curverad-right_curverad\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.undistort(frame,cameraMatrix,distCoeffs,None,cameraMatrix)\n",
    "    frame_transformed = perspective_transform(frame,source,destination)\n",
    "    binary_frame = r2b(frame_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
